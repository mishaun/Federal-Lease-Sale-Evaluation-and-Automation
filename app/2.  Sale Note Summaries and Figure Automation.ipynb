{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of Project\n",
    "\n",
    "1. Automate the process of writing notes in a natural language format of each tract in a BLM Oil and Gas Lease Sale\n",
    "\n",
    "2.  Create visualizaitons tract by tract for CEO depicting permitting, new production, and leasing activity within a given radius\n",
    "\n",
    "3.  Create a predictive model to estimate the purchase price based on historical activity, production, permits, and commodity prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of Notebook\n",
    "1.  Read in Cleaned Data for sale note generation \n",
    "2.  Create functions:\n",
    "    * Retrieve data from dataframe for tract in evaluation\n",
    "    * Write permit, recent production, old production, and leases activity summary\n",
    "    * Create visualization/charts for permits, recent production, old production, and leases data around tract\n",
    "3.  Save summaries and visualizations into Excel and Pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending Tasks\n",
    "\n",
    "* Add functionality to create concatenated dataframes for lease tracts with multiple polygons - This will create separate filters for each polygons individual centroid and compile the data as 1 dataframe for visualization and analysis\n",
    "\n",
    "* fix bug in note generation where leases with high variabliity in bonus price skews the summary (remove outliars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "import shapely\n",
    "import math\n",
    "import datetime as dt\n",
    "import pdb\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "#had to add GDAL_DATA variable to system variables and set value to the folder of gdal in C:\\Users\\mishaun\\AppData\\Local\\Continuum\\anaconda3\\Library\\share\\gdal on my work computer\n",
    "'GDAL_DATA' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'GlobalFuncts_n_Vars.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "#Running GlobalFunc_Vars script to get functions and global variables\n",
    "%run GlobalFuncts_n_Vars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tractshp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section for creating summary functions and testing logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5-10-20 VOID LINE OF CODE - new method of getting test tract by looking at dataframes read from file\n",
    "# tPerm, tProd, tLea, tOld = prepareTractFilter(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Output Data/Sale Tracts Activity Data/Leases Around Sale Tracts.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-31ce297365e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reading dataframes from excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfullFilteredLeases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output Data/Sale Tracts Activity Data/Leases Around Sale Tracts.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfullFilteredPermits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output Data/Sale Tracts Activity Data/Permits Around Sale Tracts.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfullFilteredProd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output Data/Sale Tracts Activity Data/Prod Around Sale Tracts.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfullFilteredOldProd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output Data/Sale Tracts Activity Data/OldProd Around Sale Tracts.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output Data/Sale Tracts Activity Data/Leases Around Sale Tracts.xlsx'"
     ]
    }
   ],
   "source": [
    "#reading dataframes from excel file\n",
    "fullFilteredLeases = pd.read_excel(\"Output Data/Sale Tracts Activity Data/Leases Around Sale Tracts.xlsx\")\n",
    "fullFilteredPermits = pd.read_excel(\"Output Data/Sale Tracts Activity Data/Permits Around Sale Tracts.xlsx\")\n",
    "fullFilteredProd = pd.read_excel(\"Output Data/Sale Tracts Activity Data/Prod Around Sale Tracts.xlsx\")\n",
    "fullFilteredOldProd = pd.read_excel(\"Output Data/Sale Tracts Activity Data/OldProd Around Sale Tracts.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old production must be converted back into geodata frame because the write old prod summary... ->\n",
    "#uses geospatial filtering to find wells within tract boundaries of tract\n",
    "# *** Init CRS should be initial CRS of shapefile from import because we are creating the geometries based on the lat and longs\n",
    "# *** Trying to import as a geodataframe using directly the geometry column was troublesome - geopandas did not recongize the column data type as point\n",
    "fullFilteredOldProd= gp.GeoDataFrame(fullFilteredOldProd,  crs = {'init': 'epsg:4326'}, geometry=gp.points_from_xy(fullFilteredOldProd[\"Longitude\"], fullFilteredOldProd[\"Latitude\"]))\n",
    "\n",
    "#converting oldprod geodataframe crs\n",
    "convertCRS(fullFilteredOldProd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing fuction to get data from pandas dataframe that was accessed from file\n",
    "def getActivityData(tractNum):\n",
    "    \n",
    "    '''\n",
    "    This function will filter fullFiltered global variable dataframes to tract specific data\n",
    "    '''\n",
    "    \n",
    "    tractLeases = fullFilteredLeases.loc[fullFilteredLeases[\"tract_id\"] == tractNum]\n",
    "    tractPermits = fullFilteredPermits.loc[fullFilteredPermits[\"tract_id\"] == tractNum]\n",
    "    tractProd = fullFilteredProd.loc[fullFilteredProd[\"tract_id\"] == tractNum]\n",
    "    tractOldProd = fullFilteredOldProd.loc[fullFilteredOldProd[\"tract_id\"] == tractNum]\n",
    "    \n",
    "    return tractPermits, tractProd, tractLeases, tractOldProd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test tract and retrieve data around tract\n",
    "tPerm, tProd, tLea, tOld = getActivityData(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to write permits around tract summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing out data \n",
    "\n",
    "tPerm.groupby(\"OpAlias\").count().head(3)[\"API10UWI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePermitSummary(geoDF):\n",
    "    \n",
    "    #getting overall count of permits within in the spatial filter\n",
    "    count = int(geoDF[\"API10UWI\"].count())\n",
    "    \n",
    "    if count == 0 or type(geoDF) == type(None):\n",
    "        summaryText = \"There are no permits within a 3 mile radius\"\n",
    "        return summaryText\n",
    "    \n",
    "    #stating how many permits were found based on mile radius\n",
    "    a = \"In a {} mile radius there are {} active permits\".format(miradius, count)\n",
    "    \n",
    "    #getting summary of stats for numerical columns grouped by well orientation\n",
    "    byWellType = geoDF.groupby(\"DrillType\").describe()\n",
    "    \n",
    "    \n",
    "    #creating a list comprehension to count \n",
    "    b = [(\"{:.0f} permits are {} wells \".format(byWellType[\"PermDepth\"][\"count\"].loc[i], i)) for i in byWellType.index]\n",
    "    \n",
    "    #if there were multiple types of permits, join the list with \";\", otherwise take 1st index and ocnvert to string\n",
    "    if len(byWellType)>1:\n",
    "        b = \"; \".join(b)\n",
    "    else: \n",
    "        b = b[0]\n",
    "    \n",
    "    #only talking about lateral length for horz wells\n",
    "    if 'H' in b:\n",
    "        #rounding off to the nearest thousand (-3 in the second argument of the function round\n",
    "        avgHlength = round(byWellType[\"horzLength\"][\"mean\"].loc[\"H\"],-3)\n",
    "        avgTVD = round(byWellType[\"TVD\"][\"mean\"][\"H\"], -2)\n",
    "        \n",
    "        b += \"\\nThe average lateral length among these permits is {:.0f} ft.\".format(avgHlength)\n",
    "        b += \" \\n- The TVD for these well(s) are ~{:.0f}ft\".format(avgTVD)\n",
    "    else:\n",
    "        #consider adding a standard deviation conditional analysis whether to show avg depth for V permits or min max mean type summary\n",
    "        b += \"The average TVD for the vertical permits are {:.0f}\".format(round(byWellType[\"TVD\"].loc[\"V\"][\"mean\"], -2))\n",
    "    \n",
    "    #getting top 3 operators with permits\n",
    "    topOperators = geoDF.groupby(\"OpAlias\").count().head(3)\n",
    "    \n",
    "    #list comprehension to build list with strings having operator and their permit count in 3 mi radius\n",
    "    c = [\"{} has {} permits\".format(i.title(), topOperators[\"API10UWI\"].loc[i]) for i in topOperators.index]\n",
    "    c = \", \".join(c)\n",
    "    \n",
    "    summaryText = \"\\n\".join([a,b,c])\n",
    "    \n",
    "    return summaryText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(writePermitSummary(tPerm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to write leaes around tract summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tLea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = tLea.drop_duplicates(subset=[\"Record Number\", \"Area (Acres)\", \"Bonus\"])\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted average\n",
    "sum(unique[\"Bonus\"] * unique[\"Area (Acres)\"]) / sum(unique[\"Area (Acres)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLeaseSummary(geoDF):\n",
    "    \n",
    "    #getting overall count of leases within in the spatial filter\n",
    "    count = geoDF[\"Grantee Alias\"].count()\n",
    "    \n",
    "    if count == 0:\n",
    "        return \"There are no recorded leases within a 3 mile radius\"\n",
    "    \n",
    "    #getting leases only with bonuses and dropping duplicates where lease is repeated within same section\n",
    "    leaseBonuses = geoDF[geoDF[\"Bonus\"]>0]\n",
    "    leaseBonuses = leaseBonuses.drop_duplicates(subset = ['geometry', \"Record Number\"])\n",
    "    #rounding distances to nearest tength\n",
    "    leaseBonuses[\"distance\"] = leaseBonuses[\"distance\"].apply(lambda x: round(x,1))\n",
    "    \n",
    "    #stating how many leases were found based on mile radius and most recent \n",
    "    latestYr = leaseBonuses[\"RecordYr\"].max()\n",
    "    a = \"In a {} mile radius, the latest leases with bonus information were taken in {}.\".format(miradius, latestYr)\n",
    "    \n",
    "    #getting summary of leases taken in most recent year, grouped by grantee\n",
    "    byGrantee = leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr]\n",
    "    byGrantee = byGrantee.groupby(\"Grantee Alias\").describe()\n",
    "    \n",
    "    #gtting 2 most active lessees\n",
    "    mostGrantees = byGrantee[\"Bonus\"].sort_values(\"count\", ascending = False).head(2)\n",
    "    \n",
    "    b = \"\"\n",
    "    #looping thorugh the 2 lessee's to get their average price paid\n",
    "    for i in mostGrantees.index:\n",
    "        #if the std deviation is 0 or is not available, then there is an exact price paid\n",
    "        if mostGrantees[\"std\"].loc[i] == 0 or np.isnan(mostGrantees[\"std\"].loc[i]):\n",
    "            b += \"{} paid ${:.0f}/acre.  \".format(i.title(), mostGrantees[\"mean\"].loc[i])\n",
    "        #if there is a standard deviation, then we will give the range and average\n",
    "        else:\n",
    "            b += \"{} paid between ${:.0f}/acre and ${:.0f}/acre.  \".format(i.title(), mostGrantees[\"min\"].loc[i], mostGrantees[\"max\"].loc[i])\n",
    "    \n",
    "    #if there was 2 or more lessee's for the given latest year, then report average bonus price for the data\n",
    "    if leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr][\"Bonus\"].count() > 2:\n",
    "        \n",
    "        #calculating weighted average by dropping duplicate leases by record number, bonus, and acreage\n",
    "        unique = leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr].drop_duplicates(subset=[\"Record Number\", \"Area (Acres)\", \"Bonus\"])\n",
    "        weightedAvg = sum(unique[\"Bonus\"] * unique[\"Area (Acres)\"]) / sum(unique[\"Area (Acres)\"])\n",
    "        \n",
    "        b+= \"The weighted average price in {} overall within the {} radius was ${:.0f}/acre.  \".format(latestYr,miradius,weightedAvg)\n",
    "        \n",
    "        #checking to see if highest price paid differes from the mean, if so, comment about the highest price\n",
    "        if leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr][\"Bonus\"].mean() != leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr][\"Bonus\"].max():\n",
    "            b += \"The highest price paid in {:.0f} was ${:.0f}/acre\".format(latestYr, leaseBonuses[leaseBonuses[\"RecordYr\"]==latestYr][\"Bonus\"].max())\n",
    "    \n",
    "    #generating list for previous years of latest lease taken by 4 years back\n",
    "    previousYears = list(range(latestYr-1, latestYr-4, -1))\n",
    "    \n",
    "    c = \"\"\n",
    "    for yr in previousYears:\n",
    "        #saving dataframe filtered to year of interest\n",
    "        curYr = leaseBonuses[leaseBonuses[\"Record Date\"].apply(lambda x: x.year) == yr]\n",
    "        \n",
    "        #checking to see if the dataframe has values with bonuses\n",
    "        if len(curYr)>0:\n",
    "            \n",
    "            c += \"In {}, \".format(yr)\n",
    "            \n",
    "            #grouping the filtered dataframe by year by grantee\n",
    "            grouped = curYr.groupby(\"Grantee Alias\").describe()[\"Bonus\"]\n",
    "            \n",
    "            #limiting summary to top 2 most active grantees\n",
    "            grouped = grouped.sort_values(\"count\", ascending = False).head(2)\n",
    "            \n",
    "            #looping through top 2 grantees to get their bonus range paid\n",
    "            for grantee in grouped.index:\n",
    "                \n",
    "                #if the grantee has a std of 0, then there is no variance and the average can be mentioned\n",
    "                if grouped.loc[grantee][\"std\"] == 0 or np.isnan(grouped.loc[grantee][\"std\"]):\n",
    "                    c += \"{} paid ${:.0f}/acre. \\n\".format(grantee.title(), grouped.loc[grantee][\"mean\"])\n",
    "                #if there is a std, then give the range the grantee paid\n",
    "                else:\n",
    "                    c += \"{} paid between ${:.0f}/acre and ${:.0f}/acre. \\n\".format(grantee.title(), grouped.loc[grantee][\"min\"],grouped.loc[grantee][\"max\"]) \n",
    "    \n",
    "    summaryText = \"\\n\".join([a,b,c])\n",
    "    \n",
    "    return summaryText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeLeaseSummary(tLea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 4 years of production summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 30)\n",
    "tProd\n",
    "tProd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeProdSummary(geoDF):\n",
    "    \n",
    "    #getting overall count of leases within in the spatial filter\n",
    "    overallcount = geoDF[\"APIUWI\"].count()\n",
    "    \n",
    "    if overallcount == 0:\n",
    "        return \"There are no new wells in the last 4 years within a 3 mile radius\"\n",
    " \n",
    "    a = \"There are {:.0f} wells within 3 mile radius that have started producing within last 4 years\".format(overallcount)\n",
    "    \n",
    "    if overallcount <=3:\n",
    "        b = \"\"\n",
    "        \n",
    "        for i in geoDF.index:\n",
    "            welldata = geoDF.loc[i]\n",
    "            dist, direct, op = welldata[\"distance\"], welldata[\"direction\"], welldata[\"OpAlias\"]\n",
    "            Dtype, depth = welldata[\"DrillType\"], welldata[\"TD\"]\n",
    "            totOil, totGas, monthprod = welldata[\"CumLiq\"]/1000, welldata[\"CumGas\"]/1000, welldata[\"MoProd\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "            b += \"\\n{:.2f} mi {}, {} has a {} well at {:.0f} that has made {:.0f} mbbl and {:.0f} mmcf after {:.0f} months of producing\".format(dist,direct,op.title(),Dtype,depth,totOil,totGas,monthprod)\n",
    "        \n",
    "        summaryText = '\\n'.join([a,b])\n",
    "        \n",
    "        return summaryText\n",
    "        \n",
    "    else:\n",
    "    \n",
    "\n",
    "        wellTypes = geoDF[\"DrillType\"].value_counts()  \n",
    "        b = [\"{} are {} wells\".format(wellTypes.loc[i],i) for i in wellTypes.index]\n",
    "        b = \"; \".join(b)\n",
    "\n",
    "\n",
    "        #creating bins for production months in order to describe stats (cum oil, cum gas, latest vols, etc) for wells within prod interval\n",
    "\n",
    "        bins = pd.IntervalIndex.from_tuples([(0,1), (2,3), (4,5), (6,8), (9,10), (11,12), (12,18), (19,24), (25,36), (37,48)])\n",
    "\n",
    "        geoDF[\"binsbyprodmonth\"] = pd.cut(geoDF[\"MoProd\"], bins, precision = 0)\n",
    "\n",
    "\n",
    "        #grouping the wells by their binned months producing and generating full summary\n",
    "        byBinMonth = geoDF.groupby(\"binsbyprodmonth\").describe()\n",
    "\n",
    "        #initializing empty string to build upon\n",
    "        s=\"\"\n",
    "\n",
    "        #looping through each index and generating text summary\n",
    "        for i in byBinMonth.index:\n",
    "\n",
    "            count = byBinMonth.loc[i][\"MoProd\"][\"count\"]\n",
    "\n",
    "            #if there are more than 1 well in the bin, then get a range of production along with current production\n",
    "            if  count > 1:\n",
    "                s += \"{:.0f} wells have produced for {:.0f} to {:.0f} months\".format(count, i.left, i.right)\n",
    "\n",
    "                # getting statistics for wells in bin\n",
    "                minGas = byBinMonth.loc[i][\"CumGas\"][\"min\"] / 1000\n",
    "                maxGas = byBinMonth.loc[i][\"CumGas\"][\"max\"] / 1000\n",
    "                minOil = byBinMonth.loc[i][\"CumLiq\"][\"min\"] / 1000\n",
    "                maxOil = byBinMonth.loc[i][\"CumLiq\"][\"max\"] / 1000\n",
    "\n",
    "                latestOil = byBinMonth.loc[i][\"LatestLiq\"][\"mean\"] / 30\n",
    "                latestGas = byBinMonth.loc[i][\"LatestGas\"][\"mean\"] / 30\n",
    "\n",
    "                #building string \n",
    "                s += \" and have made between {:.0f} to {:.0f} mbbls with {:.0f} to {:.0f} mmcf of gas.  \".format(minOil, maxOil, minGas, maxGas)\n",
    "                s += \"These wells are currently averaging {:.0f} bpd and {:.0f} mcfd.  \".format(latestOil, latestGas)\n",
    "\n",
    "            #if there is just 1 well in the bin, then just report the cumulative vols and current prod\n",
    "            elif count > 0:\n",
    "                oilProd = byBinMonth.loc[i][\"CumLiq\"][\"mean\"] / 1000\n",
    "                gasProd = byBinMonth.loc[i][\"CumGas\"][\"mean\"] / 1000\n",
    "                moProd = byBinMonth.loc[i][\"MoProd\"][\"mean\"]\n",
    "                latestOil = byBinMonth.loc[i][\"LatestLiq\"][\"mean\"] / 30\n",
    "                latestGas = byBinMonth.loc[i][\"LatestGas\"][\"mean\"] / 30\n",
    "\n",
    "                s += \"{:.0f} well has made {:.0f} mbbl and {:.0f} mmcfd in {:.0f} months and is currently making {:.0f} bpd and {:.0f} mcfd.  \".format(count, oilProd, gasProd, moProd, latestOil, latestGas)\n",
    "\n",
    "            \n",
    "    summaryText = \"\\n\".join([a,b,s])\n",
    "    \n",
    "    return summaryText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeProdSummary(tProd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and Log to write Old Production Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOldProdSummary(geoDF, tractNum):\n",
    "    \n",
    "    \n",
    "    #cleans up production dataframe in case import had such data values when imported from drillinginfo\n",
    "    geoDF = geoDF.loc[geoDF[\"ProdStatus\"].apply(lambda x: \"PERMIT\" not in x)]\n",
    "    \n",
    "    summaryText = ''\n",
    "    \n",
    "    if len(geoDF) == 0:\n",
    "        return \"No old wells within tract or in 3 mile radius of tract.\"\n",
    "    \n",
    "    #this line regrabs the tract geometry that has been evaluated in order to perform a more specific query of wells on the tract\n",
    "    tractBoundaries = tractshp[tractshp[\"tract_id\"] == tractNum][\"geometry\"].iloc[0]\n",
    "    \n",
    "    wellsWithinTract = geoDF.loc[geoDF.within(tractBoundaries)]\n",
    "    \n",
    "    if wellsWithinTract[\"APIUWI\"].count() > 0:\n",
    "        a = \"There are {} wells within the tract.\\n\".format(len(wellsWithinTract))\n",
    "        \n",
    "        wellTypes = wellsWithinTract[\"ProdType\"]\n",
    "        \n",
    "        #running text search to return list in order to prevent missing dry holes that may be labeled \"dry holes\" instead of just \"dry\" in DI\n",
    "        if \"DRY\" in wellTypes.value_counts():\n",
    "            \n",
    "            dryholes = list(filter(lambda x: 'DRY' in x.upper(), wellTypes.value_counts().index))\n",
    "            \n",
    "            tot = 0\n",
    "            for i in dryholes:\n",
    "                tot += wellTypes.value_counts()[i]\n",
    "                \n",
    "            \n",
    "            b = \"{} dry holes in tract.\\n\".format(tot)\n",
    "        #This will assign 0 to total if there are no dry holes\n",
    "        else:\n",
    "            tot = 0\n",
    "            b = ''\n",
    "        \n",
    "\n",
    "        \n",
    "        wellsNoInfo = wellsWithinTract[(wellsWithinTract[\"CumGas\"].isnull()) & wellsWithinTract[\"CumLiq\"].isnull()][\"APIUWI\"].count() - tot\n",
    "        \n",
    "        if wellsNoInfo>0:\n",
    "            c = '{} wells did not report production'.format(wellsNoInfo)   \n",
    "        else:\n",
    "            c = ''\n",
    "    \n",
    "        #getting dataframe with wells that reported production within tract; how = 'all' fixes error of dropping all rows b/c only 1 column of the 2 is null.\n",
    "        #how = 'all' ensures both columns are null to be dropped\n",
    "        wellsInTractProd = wellsWithinTract.dropna(subset = [\"CumGas\", \"CumLiq\"], how = \"all\")\n",
    "        \n",
    "        d= \"\"\n",
    "        #checking how many wells reported production, ~ symbol is to get not null values\n",
    "        if wellsInTractProd[\"APIUWI\"].count()>0:\n",
    "            d += \"{} wells reported production.  They produced: \".format(wellsInTractProd[\"APIUWI\"].count())\n",
    "            \n",
    "            for well in wellsInTractProd.index:\n",
    "                \n",
    "                oil = wellsInTractProd.loc[well][\"CumLiq\"] / 1000\n",
    "                gas = wellsInTractProd.loc[well][\"CumGas\"] / 1000\n",
    "                yearsProd = str(wellsInTractProd.loc[well][\"FstPrdDate\"].year) + \"-\" + str(wellsInTractProd.loc[well][\"LstPrdDate\"].year)\n",
    "                md = wellsInTractProd.loc[well][\"TD\"]\n",
    "                \n",
    "                #checks if oil or gas has a null value, if so, it will make it 0 instead of nan\n",
    "                if np.isnan(oil):\n",
    "                    oil = 0\n",
    "                if np.isnan(gas):\n",
    "                    gas = 0\n",
    "            \n",
    "                d += \"{:.0f} mbbl and {:.0f} mmcf at {:.0f} ft from years {}, \".format(oil, gas, md, yearsProd)\n",
    "        \n",
    "        summaryText = a + b + c + d\n",
    "    else:\n",
    "        summaryText = \"There are no wells within tract boundaries \\n\"\n",
    "    \n",
    "    #getting wells outside the tract for another analysis - the '~' character works as the \"not within\" condition        \n",
    "    wellsOutside = geoDF.loc[~geoDF.within(tractBoundaries)]\n",
    "    \n",
    "    if wellsOutside[\"APIUWI\"].count()>0:\n",
    "        summaryText += \"\\nThere are ~{} wells outside the tract within a 3 mile radius.\\n\".format(wellsOutside[\"APIUWI\"].count())\n",
    "        \n",
    "        wellsNoInfo = wellsOutside[(wellsOutside[\"CumGas\"].isnull()) & wellsOutside[\"CumLiq\"].isnull()][\"APIUWI\"].count()\n",
    "        \n",
    "        if wellsNoInfo>0:\n",
    "            \n",
    "            dryholes = wellsOutside[wellsOutside[\"ProdType\"] == \"DRY\"].iloc[:,0].count()\n",
    "            \n",
    "            summaryText += \"Out of these, {} were dry.\\n\".format(dryholes)\n",
    "        \n",
    "            if wellsNoInfo-dryholes != 0:\n",
    "                summaryText += \"{} do not have reported production. \\n\".format(wellsNoInfo - dryholes)\n",
    "            \n",
    "        topWells = wellsOutside.sort_values(\"CumBOE\", ascending = False).dropna(subset=[\"CumGas\", \"CumLiq\"])\n",
    "\n",
    "        if topWells[\"APIUWI\"].count() > 0:\n",
    "\n",
    "            summaryText += \"The top wells that produced made: \"\n",
    "\n",
    "            for well in topWells.head().index:\n",
    "                \n",
    "                oil = topWells.loc[well][\"CumLiq\"] / 1000\n",
    "                gas = topWells.loc[well][\"CumGas\"] / 1000\n",
    "                td = topWells.loc[well][\"TD\"]\n",
    "                moprod = topWells.loc[well][\"MoProd\"]\n",
    "                yearsProdInterval = str(topWells.loc[well][\"FstPrdDate\"].year) + \"-\" + str(topWells.loc[well][\"LstPrdDate\"].year)\n",
    "\n",
    "                summaryText += \"{:.0f} mbbl and {:.0f} mmcf at {:.0f} ft in {:.0f} months from {}; \".format(oil, gas, td, moprod, yearsProdInterval)\n",
    "        \n",
    "    return summaryText\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOldProdSummary(tOld, 37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section for creating statistical plots for permit, leases, and production data & mapping for parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Plots and Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPermitDash(per, tractNum):\n",
    "    '''This function will create a dashboard describing the permits (per dataframe) around a sale parcel with tractNum'''\n",
    "    \n",
    "    if len(per)>0:\n",
    "\n",
    "        #creating matplotlib figure\n",
    "        dashPermits, permitAxes = plt.subplots(2,2, figsize = (12,8))\n",
    "\n",
    "        #inserting barplot showing count of permits by their well status\n",
    "        sns.countplot(per[\"WellStatus\"], palette = \"rainbow\", ax=permitAxes[0,0])\n",
    "        permitAxes[0,0].set_title(\"Permits by Well Status\")\n",
    "\n",
    "        #inserting subplot onto figure showing permits taken by operator\n",
    "        sns.countplot(per[\"OpAlias\"], ax = permitAxes[0,1])\n",
    "        permitAxes[0,1].set_title(\"Permits by Operator\")\n",
    "\n",
    "        #inserting subplot of permits by drill type\n",
    "        sns.countplot(per[\"DrillType\"], ax = permitAxes[1,0])\n",
    "        permitAxes[1,0].set_title(\"Permits by Well Type (H,D,V)\")\n",
    "\n",
    "        #This will prevent the plot from creating when there is not horzLength column due to the permits not being horizontal\n",
    "        try:\n",
    "            sns.distplot(per[\"horzLength\"],bins = 5, ax = permitAxes[1,1], kde = False)\n",
    "            permitAxes[1,1].set_xlim([0,15000])\n",
    "            permitAxes[1,1].set_title(\"Permit Horizontal Lengths - Binned\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        dashPermits.suptitle('Permit Summary for Tract {}\\n Total permits: {}'.format(tractNum, len(per)), y = 1.05, fontsize = 20, fontweight = 15)\n",
    "\n",
    "\n",
    "        dashPermits.tight_layout()\n",
    "\n",
    "        return dashPermits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLeasesDash(lea, tractNum):\n",
    "    \n",
    "    '''\n",
    "    This function will take in a dataframe of lease information, lea\n",
    "    and create a dashboard of lease stats around the tract tractNum\n",
    "    '''\n",
    "    \n",
    "    if len(lea)>0:\n",
    "    \n",
    "        #getting leases only with bonuses and dropping duplicates where lease is repeated within same section\n",
    "        lea = lea[lea[\"Bonus\"]>0]\n",
    "        lea = lea.drop_duplicates(subset = ['geometry', \"Record Number\"])\n",
    "\n",
    "        dashLease, leaseAx = plt.subplots(3,1, figsize = (16,20))\n",
    "\n",
    "        #creating format for y tickers\n",
    "        formatter = ticker.FormatStrFormatter('$%1.0f')\n",
    "\n",
    "        #inserting a swarmplot showing bonus by record year colored by grantee\n",
    "        sns.swarmplot(lea[\"RecordYr\"], lea[\"Bonus\"], size = 10, hue = lea[\"Grantee Alias\"], ax = leaseAx[0])\n",
    "        leaseAx[0].set_title(\"Lease Bonus by Year - Swarmplot\")\n",
    "\n",
    "        #inserting scatter plot showing bonuses away from centroid of tract\n",
    "        sns.scatterplot(lea[\"distance\"], lea[\"Bonus\"], style = lea[\"direction\"], alpha=.7, hue = lea[\"RecordYr\"], palette=\"gist_rainbow\", s = 150, ax = leaseAx[1])\n",
    "        leaseAx[1].set_title(\"Lease Price by Distance of Sale Parcel\")\n",
    "\n",
    "        #barplot of grantee, bonus, and year\n",
    "        sns.barplot(lea[\"RecordYr\"], lea[\"Bonus\"], hue = lea[\"Grantee Alias\"], ax = leaseAx[2])\n",
    "        leaseAx[2].set_title(\"Lease Price by Grantee\")\n",
    "\n",
    "        #top level title statas\n",
    "        latestYr = lea[\"RecordYr\"].max()\n",
    "        avgPriceLatestYr = lea[lea[\"RecordYr\"] == latestYr][\"Bonus\"].mean()\n",
    "\n",
    "        #setting all axes on figure to dollar sign format\n",
    "        for ax in leaseAx:\n",
    "            ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        #y = 1.03 will move up the subplot title above the first plot's title so they don't overlap\n",
    "        dashLease.suptitle(\"Lease Summary for tract {} \\n Total Number of Leases: {} \\n Average Price ${:.0f}/acre in {}\".format(tractNum, len(lea), avgPriceLatestYr, latestYr), y = 1.05, fontsize = 20, fontweight = 15)\n",
    "\n",
    "        dashLease.tight_layout()\n",
    "\n",
    "        return dashLease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createProdDash(pro, tractNum):\n",
    "    '''This function will take in a geopandas data frame -pro- and create the following plots below onto 1 figure'''\n",
    "    \n",
    "    #will only create figure if there is production in the dataframe, otherwise it will not return anything\n",
    "    if len(pro)>0:\n",
    "    \n",
    "        dashProd, prodAx = plt.subplots(3,1, figsize=(16,20))\n",
    "\n",
    "        sns.scatterplot(pro[\"CumGas\"], pro[\"CumLiq\"], s = 150, hue = pro[\"MoProd\"], ax = prodAx[0])\n",
    "        prodAx[0].set_title(\"Scatter Plot - Cumulative Gas vs Cumalative Oil - Colored by Months Produced\")\n",
    "\n",
    "        sns.scatterplot(pro[\"MoProd\"], pro[\"CumLiq\"], s = 150, hue = pro[\"OpAlias\"], ax = prodAx[1])\n",
    "        prodAx[1].set_title(\"Cumaltive Oil vs. Months Produced - Colored by Operator\")\n",
    "\n",
    "        sns.scatterplot(pro[\"MoProd\"], pro[\"CumGas\"], s = 150, hue = pro[\"OpAlias\"], ax = prodAx[2])\n",
    "        prodAx[2].set_title(\"Cumalative Gas vs. Months Produced - Colored by Operator\")\n",
    "        \n",
    "        dashProd.tight_layout()\n",
    "        dashProd.suptitle(\"Production Dashboard for tract {}\".format(tractNum), y = 1.03, fontsize = 20, fontweight = 15)\n",
    "\n",
    "        return dashProd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOldProdDash(OldProd, tractNum):\n",
    "    \n",
    "    if len(OldProd)>0:\n",
    "        \n",
    "        #retrieving boundary of tract to look at wells wtihin and outside of tract\n",
    "        #tractshp must be a global variable in the script\n",
    "        tractBoundary = tractshp.loc[tractshp[\"tract_id\"]==tractNum][\"geometry\"].iloc[0]\n",
    "\n",
    "        outsideTract = OldProd.loc[~OldProd.within(tractBoundary)]\n",
    "        insideTract = OldProd.loc[OldProd.within(tractBoundary)]\n",
    "\n",
    "        #Creating plots for wells outside of tract\n",
    "        fig1, ax1 = plt.subplots(4,1, figsize = (16,20))\n",
    "\n",
    "        sns.scatterplot(outsideTract[\"MoProd\"], outsideTract[\"CumLiq\"], s = 150, palette = \"rainbow\", hue = outsideTract[\"TD\"], ax = ax1[0])\n",
    "        ax1[0].set_title(\"Cumulative Oil vs. Months Produced\")\n",
    "\n",
    "        sns.scatterplot(outsideTract[\"MoProd\"], outsideTract[\"CumGas\"], s = 150, palette = \"rainbow\", hue = outsideTract[\"TD\"], ax = ax1[1])\n",
    "        ax1[1].set_title(\"Cumulative Gas vs. Months Produced\")\n",
    "        ax1[1].grid()\n",
    "\n",
    "        keyProdTypes = [\"OIL\", \"GAS\", \"DRY\", \"DRY HOLE\", \"CBM\"]\n",
    "        sns.countplot(outsideTract[\"ProdType\"].loc[outsideTract[\"ProdType\"].isin(keyProdTypes)], ax = ax1[2])\n",
    "        ax1[2].set_title(\"Production Types Around Tract\")\n",
    "\n",
    "        keyProdStatus = \"ACTIVE, INACTIVE, SHUT-IN, SHUT IN, P&A, P & A, PLUGGED\".split(', ')\n",
    "        sns.countplot(outsideTract[\"ProdStatus\"].loc[outsideTract[\"ProdStatus\"].isin(keyProdStatus)], ax=ax1[3])\n",
    "        ax1[3].set(title = \"Status of Wells\")\n",
    "\n",
    "        fig1.suptitle(\"Old Production Outside of Tract {} - 3 Mi Radius\".format(tractNum), y = 1.03, fontsize = 20, fontweight = 15)\n",
    "\n",
    "        fig1.tight_layout()\n",
    "        \n",
    "        #Creating plots for wells within tract, if there are any\n",
    "\n",
    "        if len(insideTract) > 0:\n",
    "\n",
    "            fig2, ax2 = plt.subplots(3,1, figsize = (16,20))\n",
    "\n",
    "            keyProdTypes = [\"OIL\", \"GAS\", \"DRY\", \"DRY HOLE\", \"CBM\"]\n",
    "            sns.countplot(insideTract[\"ProdType\"].loc[insideTract[\"ProdType\"].isin(keyProdTypes)], ax = ax2[0])\n",
    "            ax2[0].set_title(\"Production Types Around Tract\")\n",
    "\n",
    "            sns.scatterplot(insideTract[\"MoProd\"], insideTract[\"CumLiq\"], s = 150, palette = \"rainbow\", hue = insideTract[\"TD\"], ax = ax2[1])\n",
    "            ax2[1].set_title(\"Cumulative Oil vs. Months Produced\")\n",
    "\n",
    "            sns.scatterplot(insideTract[\"MoProd\"], insideTract[\"CumGas\"], s = 150, palette = \"rainbow\", hue = insideTract[\"TD\"], ax = ax2[2])\n",
    "            ax2[2].set_title(\"Cumulative Gas vs. Months Produced\")\n",
    "            ax2[2].grid()\n",
    "\n",
    "            fig2.suptitle(\"Old Production Inside of Tract {} - 3 Mi Radius\".format(tractNum), y = 1.03, fontsize = 20, fontweight = 15)\n",
    "            fig2.tight_layout()\n",
    "\n",
    "            return fig1, fig2\n",
    "\n",
    "        return fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Tract\n",
    "a,b,c,d = getActivityData(16)\n",
    "\n",
    "writeOldProdSummary(d, 16)\n",
    "createOldProdDash(d,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test loop\n",
    "\n",
    "# perdashboard = []\n",
    "# proddashboard = []\n",
    "# leasedashboard = []\n",
    "\n",
    "# for i in range(15,17):\n",
    "    \n",
    "#     tract = tractshp[\"tract_id\"].iloc[i]\n",
    "    \n",
    "#     a, b, c, d = prepareTractFilter(tract)\n",
    "    \n",
    "#     perdashboard.append(createPermitDash(a,tract))\n",
    "#     proddashboard.append(createProdDash(b, tract))\n",
    "#     leasedashboard.append(createLeasesDash(c, tract))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running summary functions in loop to get summaries for all tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty array to append summaries to for each tract\n",
    "summaryPermits = []\n",
    "summaryProd = []\n",
    "summaryLeases = []\n",
    "summaryOldProd = []\n",
    "\n",
    "#creating arrays to append visual plots for each tract\n",
    "perdashboard = []\n",
    "proddashboard = []\n",
    "leasedashboard = []\n",
    "oldproddashboard = []\n",
    "\n",
    "#looping through each tract id and creating filtered geospatial data, activity summaries, and visualizaiton plots\n",
    "for i in tractshp[\"tract_id\"]:\n",
    "    perm, prod, leases, oldprodtoeval = getActivityData(i) \n",
    "    \n",
    "    try:\n",
    "        summaryPermits.append(writePermitSummary(perm))\n",
    "    except:\n",
    "        summaryPermits.append(\"error occured\")\n",
    "        \n",
    "    try:\n",
    "        summaryProd.append(writeProdSummary(prod))\n",
    "    except:\n",
    "        summaryProd.append(\"error occured\")\n",
    "        \n",
    "    try:\n",
    "        summaryLeases.append(writeLeaseSummary(leases))\n",
    "    except: \n",
    "        summaryLeases.append(\"error occured\")\n",
    "\n",
    "    try:\n",
    "        summaryOldProd.append(writeOldProdSummary(oldprodtoeval, i))\n",
    "    except: \n",
    "        summaryOldProd.append(\"error occured\")\n",
    "\n",
    "    #appending visualizaiton plots to list    \n",
    "    perdashboard.append(createPermitDash(perm,i))\n",
    "    proddashboard.append(createProdDash(prod, i))\n",
    "    leasedashboard.append(createLeasesDash(leases, i))  \n",
    "    oldproddashboard.append(createOldProdDash(oldprodtoeval, i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending Results of mass loop of applying summary functions and visualization plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending columns to tract list with summaries for each data type (old prod, leases, permits, new production)\n",
    "tractshp[\"Permit Summary\"] = summaryPermits\n",
    "\n",
    "tractshp[\"Leases Summary\"] = summaryLeases\n",
    "\n",
    "tractshp[\"Old Production Summary\"] = summaryOldProd\n",
    "\n",
    "tractshp[\"Recent Prod Summary\"] = summaryProd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractshp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Summary Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving activity notes in an excel file in the results folder - dropping geopandas required geo cols\n",
    "tractshp.drop(columns = \"geometry centroids buffers\".split(\" \")).to_excel(\"Results/Activity Summary Notes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipping individual corresponding plots for each tract into one master list\n",
    "MasterDash = list(zip(perdashboard, proddashboard, leasedashboard, oldproddashboard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in MasterDash:\n",
    "    for figures in item:\n",
    "        figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving visualizations in results subfolder called viz\n",
    "import matplotlib.backends.backend_pdf\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"Results/Permits Leases and Prod Visualizations.pdf\")\n",
    "\n",
    "#loooping through each set of figures for each tract, saving them to pdf\n",
    "for items in MasterDash:\n",
    "    for fig in items: \n",
    "        try:\n",
    "            #bbox = tight is to make sure plot titles aren't cut off that have been shifted up\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "        except:\n",
    "            print(\"Error Occured - Most likely null figure\")\n",
    "        \n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
